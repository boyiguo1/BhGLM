---
title: "Method Evaluation"
author: "Boyi Guo"
date: "1/19/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message= F)
library(BhGLM)
library(tidyverse)
library(grid)
library(ggeffects)
library(ggplot2)
library(gridExtra)
library(splines)
library(mgcv)


Sl.setup <- function(G,cholesky=FALSE) {
  ## Sets up a list representing a block diagonal penalty matrix.
  ## from the object produced by `gam.setup'.
  ## Uses only pivoted Cholesky if cholesky==TRUE.
  ## Return object is a list, Sl, with an element for each block.
  ## For block, b, Sl[[b]] is a list with the following elements
  ## * repara - should re-parameterization be applied to model matrix etc 
  ##            usually false if  non-linear in coefs
  ## * start, stop: start:stop indexes the parameters of this block
  ## * S a list of penalty matrices for the block (dim = stop-start+1)
  ##   - If length(S)==1 then this will be an identity penalty.
  ##   - Otherwise it is a multiple penalty, and an rS list of square
  ##     root penalty matrices will be added. S (if repara) and rS (always) 
  ##     will be projected into range space of total penalty matrix.
  ##     If cholesky==TRUE then rS contains the projected S if !repara and otherwise
  ##     rS not returned (since S contains same thing).
  ## * rS sqrt penalty matrices if it's a multiple penalty and cholesky==FALSE.
  ##      projected penalty if cholesky==TRUE and !repara. NULL otherwise. 
  ## * D a reparameterization matrix for the block
  ##   - Applies to cols/params from start:stop.
  ##   - If numeric then X[,start:stop]%*%diag(D) is repara X[,start:stop],
  ##     b.orig = D*b.repara
  ##   - If matrix then X[,start:stop]%*%D is repara X[,start:stop],
  ##     b.orig = D%*%b.repara
  ## * Di is inverse of D, but is only supplied if D is not orthogonal, or
  ##   diagonal.
  ## The penalties in Sl are in the same order as those in G
  ## Also returns attribute "E" a square root of the well scaled total
  ## penalty, suitable for rank deficiency testing, and attribute "lambda"
  ## the corresponding smoothing parameters.  
  ##if (!is.null(G$H)) stop("paraPen min sp not supported")
  
  Sl <- list()
  b <- 1
  ## now work through the smooths....
  if (length(G$smooth)) 
    
    for (i in 1:length(G$smooth)) {
      
      if (!is.null(G$smooth[[i]]$fixed)&&G$smooth[[i]]$fixed)
        m <- 0
      else
        m <- length(G$smooth[[i]]$S)
      
      if (m>0) {
        Sl[[b]] <- list()
        Sl[[b]]$start <- G$smooth[[i]]$first.para
        Sl[[b]]$stop <- G$smooth[[i]]$last.para    
        ## if the smooth has a g.index field it indicates non-linear params,
        ## in which case re-parameterization will usually break the model!
        Sl[[b]]$repara <- if (is.null(G$smooth[[i]]$g.index)) TRUE else FALSE 
      }
      
      if (m==0) {} else ## fixed block
        if (m==1) { ## singleton
          
          Sl[[b]]$rank <- G$smooth[[i]]$rank  
          Sl[[b]]$S <- G$smooth[[i]]$S
          Sl[[b]]$lambda <- 1
          b <- b + 1
          
        }
    }
  
  ## At this stage Sl contains the penalties, identified as singletons or 
  ## multiple S blocks. Now the blocks need re-parameterization applied.
  ## Singletons need to be transformed to identity penalties, while 
  ## multiples need to be projected into total penalty range space. 
  
  if (length(Sl)==0) return(Sl) ## nothing to do
  
  np <- ncol(G$X)
  E <- matrix(0,np,np) ## well scaled square root penalty
  lambda <- rep(0,0)
  
  for (b in 1:length(Sl)) { ## once more into the blocks, dear friends...
    if (length(Sl[[b]]$S)==1) { ## then we have a singleton
      if (sum(abs(Sl[[b]]$S[[1]][upper.tri(Sl[[b]]$S[[1]],diag=FALSE)]))==0) { ## S diagonal
        ## Reparameterize so that S has 1's or zero's on diagonal
        ## In new parameterization smooth specific model matrix is X%*%diag(D)
        ## ind indexes penalized parameters from this smooth's set. 
        D <- diag(Sl[[b]]$S[[1]])
        ind <- D > 0 ## index penalized elements 
        D[ind] <- 1/sqrt(D[ind]);D[!ind] <- 1 ## X' = X%*%diag(D) 
        Sl[[b]]$D <- D; Sl[[b]]$ind <- ind
      } else { ## S is not diagonal
        if (cholesky) { ## use Cholesky based reparameterization
          tr <- singleStrans(Sl[[b]]$S[[1]],Sl[[b]]$rank)
          ind <- rep(FALSE,ncol(tr$D))
          ind[1:tr$rank] <- TRUE
          Sl[[b]]$D <- tr$D
          Sl[[b]]$Di <- tr$Di
          Sl[[b]]$rank <- tr$rank
        } else { ## use eigen based re-parameterization
          es <- eigen(Sl[[b]]$S[[1]],symmetric=TRUE)
          U <- es$vectors;D <- es$values
          if (is.null(Sl[[b]]$rank)) { ## need to estimate rank
            Sl[[b]]$rank <- sum(D>.Machine$double.eps^.8*max(D))
          }
          ind <- rep(FALSE,length(D))
          ind[1:Sl[[b]]$rank] <- TRUE ## index penalized elements
          D[ind] <- 1/sqrt(D[ind]);D[!ind] <- 1
          Sl[[b]]$D <- t(D*t(U)) ## D <- U%*%diag(D)
          Sl[[b]]$Di <- t(U)/D
        }  
        ## so if X is smooth model matrix X%*%D is re-parameterized form
        ## and t(D)%*%Sl[[b]]$S[[1]]%*%D is the reparameterized penalty
        ## -- a partial identity matrix.
        ## Di is the inverse of D and crossprod(Di[1:rank,]) is the original
        ## penalty matrix
        Sl[[b]]$ind <- ind
      }
      ## add penalty square root into E  
      if (Sl[[b]]$repara) { ## then it is just the identity
        ind <- (Sl[[b]]$start:Sl[[b]]$stop)[Sl[[b]]$ind]
        diag(E)[ind] <- 1
        lambda <- c(lambda,1) ## record corresponding lambda
      } else { ## need scaled root penalty in *original* parameterization
        D <- Sl[[b]]$Di[1:Sl[[b]]$rank,]
        D.norm <- norm(D); D <- D/D.norm
        indc <- Sl[[b]]$start:(Sl[[b]]$start+ncol(D)-1)
        indr <- Sl[[b]]$start:(Sl[[b]]$start+nrow(D)-1)
        E[indr,indc] <- D
        lambda <- c(lambda,1/D.norm^2)
      }
    } 
  } ## re-para finished
  attr(Sl,"E") <- E ## E'E = scaled total penalty
  attr(Sl,"lambda") <- lambda ## smoothing parameters corresponding to E
  attr(Sl,"cholesky") <- cholesky ## store whether this is Cholesky based or not
  Sl ## the penalty list
} ## end of Sl.setup


Sl.initial.repara <- function(Sl,X,inverse=FALSE,both.sides=TRUE,cov=TRUE,nt=1) {
  ## Routine to apply initial Sl re-parameterization to model matrix X,
  ## or, if inverse==TRUE, to apply inverse re-para to parameter vector 
  ## or cov matrix. If inverse is TRUE and both.sides=FALSE then 
  ## re-para only applied to rhs, as appropriate for a choleski factor.
  ## If both.sides==FALSE, X is a vector and inverse==FALSE then X is
  ## taken as a coefficient vector (so re-para is inverse of that for model
  ## matrix...)
  if (length(Sl)==0) return(X) ## nothing to do
  if (inverse) { ## apply inverse re-para
    if (is.matrix(X)) { 
      if (cov) { ## then it's a covariance matrix
        for (b in 1:length(Sl)) if (Sl[[b]]$repara) { 
          ind <- Sl[[b]]$start:Sl[[b]]$stop
          if (is.matrix(Sl[[b]]$D)) { 
            if (both.sides) X[ind,] <- if (nt==1) Sl[[b]]$D%*%X[ind,,drop=FALSE] else 
              pmmult(Sl[[b]]$D,X[ind,,drop=FALSE],FALSE,FALSE,nt=nt)
            X[,ind] <- if (nt==1) X[,ind,drop=FALSE]%*%t(Sl[[b]]$D) else
              pmmult(X[,ind,drop=FALSE],Sl[[b]]$D,FALSE,TRUE,nt=nt)
          } else { ## Diagonal D
            X[,ind] <- t(Sl[[b]]$D * t(X[,ind,drop=FALSE]))
            if (both.sides) X[ind,] <- Sl[[b]]$D * X[ind,,drop=FALSE]
          } 
        } 
      } else { ## regular matrix: need to use Di
        for (b in 1:length(Sl)) if (Sl[[b]]$repara) { 
          ind <- Sl[[b]]$start:Sl[[b]]$stop
          if (is.matrix(Sl[[b]]$D)) { 
            Di <- if(is.null(Sl[[b]]$Di)) t(Sl[[b]]$D) else Sl[[b]]$Di
            if (both.sides) X[ind,] <- if (nt==1) t(Di)%*%X[ind,,drop=FALSE] else
              pmmult(Di,X[ind,,drop=FALSE],TRUE,FALSE,nt=nt)
            X[,ind] <- if (nt==1) X[,ind,drop=FALSE]%*%Di else
              pmmult(X[,ind,drop=FALSE],Di,FALSE,FALSE,nt=nt)
          } else { ## Diagonal D
            Di <- 1/Sl[[b]]$D
            X[,ind] <- t(Di * t(X[,ind,drop=FALSE]))
            if (both.sides) X[ind,] <- Di * X[ind,,drop=FALSE]
          } 
        } 
      }
    } else { ## it's a parameter vector
      for (b in 1:length(Sl)) if (Sl[[b]]$repara) { 
        ind <- Sl[[b]]$start:Sl[[b]]$stop
        if (is.matrix(Sl[[b]]$D)) X[ind] <- Sl[[b]]$D%*%X[ind] else 
          X[ind] <- Sl[[b]]$D*X[ind] 
      }
    }
  } else for (b in 1:length(Sl)) if (Sl[[b]]$repara) { ## model matrix re-para
    ind <- Sl[[b]]$start:Sl[[b]]$stop
    if (is.matrix(X)) { 
      if (is.matrix(Sl[[b]]$D)) { 
        if (both.sides)  X[ind,] <- if (nt==1) t(Sl[[b]]$D)%*%X[ind,,drop=FALSE] else 
          pmmult(Sl[[b]]$D,X[ind,,drop=FALSE],TRUE,FALSE,nt=nt)
        X[,ind] <- if (nt==1) X[,ind,drop=FALSE]%*%Sl[[b]]$D else
          pmmult(X[,ind,drop=FALSE],Sl[[b]]$D,FALSE,FALSE,nt=nt)
      } else { 
        if (both.sides) X[ind,] <- Sl[[b]]$D * X[ind,,drop=FALSE]
        X[,ind] <- t(Sl[[b]]$D*t(X[,ind,drop=FALSE])) ## X[,ind]%*%diag(Sl[[b]]$D)
      }
    } else {
      if (both.sides) { ## signalling vector to be treated like model matrix X... 
        if (is.matrix(Sl[[b]]$D)) X[ind] <- t(Sl[[b]]$D)%*%X[ind] else 
          X[ind] <- Sl[[b]]$D*X[ind]
      } else { ## both.sides == FALSE is just a signal that X is a parameter vector
        if (is.matrix(Sl[[b]]$D)) X[ind] <-
            if (is.null(Sl[[b]]$Di)) t(Sl[[b]]$D)%*%X[ind] else Sl[[b]]$Di%*%X[ind] else
              X[ind] <- X[ind]/Sl[[b]]$D
      }
    }
  }
  X
} ## end Sl.initial.repara
```

## Data Simulation
```{r}
N <- 1000
p <- 4

set.seed(1)

tmp <- sim_Bai_logistic(N, p)
dat <- tmp$dat %>% data.frame
theta <- tmp$theta

```

```{r}
f_x1 <- function(x){
  lp <- 5*sin(2*pi*x)
  return(exp(lp)/(1+exp(lp)))
}

f_x2 <- function(x){
  lp <- - 4*cos(2*pi*x-0.5)
    return(exp(lp)/(1+exp(lp)))
}

f_x3 <- function(x){
  lp <- 6*(x-0.5)
    return(exp(lp)/(1+exp(lp)))
}

f_x4 <- function(x){
  lp <- -5*(x^2-0.3)
    return(exp(lp)/(1+exp(lp)))
}

true_p1 <- ggplot(data.frame(x = c(-3, 3)), aes(x=x)) + stat_function(fun = f_x1) + ylab("Response") + xlab("x1")
true_p2 <- ggplot(data.frame(x = c(-3, 3)), aes(x=x)) + stat_function(fun = f_x2) + ylab("Response") + xlab("x2")
true_p3 <- ggplot(data.frame(x = c(-3, 3)), aes(x=x)) + stat_function(fun = f_x3) + ylab("Response") + xlab("x3")
true_p4 <- ggplot(data.frame(x = c(-3, 3)), aes(x=x)) + stat_function(fun = f_x4) + ylab("Response") + xlab("x4")
grid.arrange(true_p1, true_p2, true_p3, true_p4, nrow=2, ncol=2, 
             top=textGrob("Data Generating Functions",gp=gpar(fontsize=20,font=3)))


```



## MGCV model

```{r echo=T}
mgcv_mdl <- gam(y ~ s(x1, bs = "ps")+s(x2, bs = "ps")+s(x3, bs = "ps")+s(x4, bs = "ps"), 
         data=dat %>% data.frame(), family=binomial, drop.intercept = F)
# summary(mgcv_mdl)
```

```{r}
ma = ggpredict(mgcv_mdl, terms="x1") 
p1 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(mgcv_mdl, terms="x2") 
p2 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(mgcv_mdl, terms="x3") 
p3 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(mgcv_mdl, terms="x4") 
p4 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
grid.arrange(p1, p2, p3, p4, nrow=2, ncol=2, 
             top=textGrob("mgcv Model Estimation",gp=gpar(fontsize=20,font=3)))
```

## Navie Bhglm
```{r echo=T}
naive_bglm <- bglm(y ~ bs(x1,df=13)+bs(x2,df=13)+bs(x3,df=13)+bs(x4,df=13)-1, 
          data=dat %>% data.frame, family=binomial, 
          # TODO : adjust the grouping
          group=c(0,13,26,39, 52),
          prior=mt(mean=0, s0=0.04, s1=1, df=Inf))
```

```{r}

ma = ggpredict(naive_bglm, terms="x1") 
p1 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(naive_bglm, terms="x2") 
p2 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(naive_bglm, terms="x3") 
p3 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(naive_bglm, terms="x4") 
p4 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
grid.arrange(p1, p2, p3, p4, nrow=2, ncol=2, 
             top=textGrob("Naive group bglm Model Estimation",gp=gpar(fontsize=20,font=3)))
```


## Navie bhglm_spline
```{r, echo=T}
navie_bam <- bglm_spline(y ~ bs(x1,df=15)+bs(x2,df=15)+bs(x3,df=15)+bs(x4,df=15)-1, 
          data=dat %>% data.frame, family=binomial, 
          # TODO : adjust the group
          group=c(0,15,30,45, 60),
          prior=mt(mean=0, s0=0.04, s1=1, df=Inf))
```

```{r}

ma = ggpredict(navie_bam, terms="x1") 
p1 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(navie_bam, terms="x2") 
p2 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(navie_bam, terms="x3") 
p3 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
ma = ggpredict(navie_bam, terms="x4") 
p4 = plot(ma, show.title=F) + ylab("Response") +
  geom_rug(sides="b", colour="grey")
grid.arrange(p1, p2, p3, p4, nrow=2, ncol=2, 
             top=textGrob("Shared Indicator group bglm Model Estimation",gp=gpar(fontsize=20,font=3)))
```


## bhglm_spline
```{r}
G <- gam(y ~ s(x1, bs = "ps")+s(x2, bs = "ps")+s(x3, bs = "ps")+s(x4, bs = "ps"), 
         data=dat %>% data.frame(), family=binomial,drop.intercept = TRUE, fit = FALSE)

create_group <- function(G, drop.intercept=FALSE)
{
  m <- length(G$smooth)
  
  group <- c(G$smooth[[1]]$first.para-1,
             map_dbl(G$smooth, .f = function(x){x$last.para}))
  
  
  if(drop.intercept == TRUE)
    group <- group - 1
  # TODO: consider if drop.intercept is needed. in this case, drop.intercept should be aligned with if the new formula have intercept, which possibly alter the position of the groups
  return(group)
}


bgam_mdl <- bglm_spline(G$y~G$X-1, family = G$family, prior=mt(mean=0, s0=0.04, s1=1, df=Inf),
     group = create_group(G, TRUE))

lp_x1 <- G$X[,1:9]%*%coefficients(bgam_mdl)[1:9]
p1 <- ggplot(data.frame(x1 = dat$x1, y = exp(lp_x1)/(1+exp(lp_x1))),
       aes(x = x1, y = y)) + geom_point() + ylab("Response")

lp_x2 <- G$X[,10:18]%*%coefficients(bgam_mdl)[10:18]
p2 <- ggplot(data.frame(x2 = dat$x2, y = exp(lp_x2)/(1+exp(lp_x2))),
       aes(x = x2, y = y)) + geom_point() + ylab("Response")

lp_x3 <- G$X[,19:27]%*%coefficients(bgam_mdl)[19:27]
p3 <- ggplot(data.frame(x3 = dat$x3, y = exp(lp_x3)/(1+exp(lp_x3))),
       aes(x = x3, y = y)) + geom_point() + ylab("Response")

lp_x4 <- G$X[,28:36]%*%coefficients(bgam_mdl)[28:36]
p4 <- ggplot(data.frame(x4 = dat$x4, y = exp(lp_x4)/(1+exp(lp_x4))),
       aes(x = x4, y = y)) + geom_point() + ylab("Response")

grid.arrange(p1, p2, p3, p4, nrow=2, ncol=2, 
             top=textGrob("Shared Indicator group bglm Model Estimation with mgcv splines",gp=gpar(fontsize=20,font=3)))

```




```{r, eval=F, echo=F}

 G$Sl <- Sl.setup(G) ## prepare penalty sequence
G$X <- Sl.initial.repara(G$Sl,G$X,both.sides=FALSE) ## re-parameterize accordingly

repa_mdl <- bglm_spline(G$y~G$X, family = G$family, prior=mt(mean=0, s0=0.04, s1=1, df=Inf),
     group = create_group(G))

lp_x1 <- G$X[,1:9]%*%coefficients(bgam_mdl)[1:9]
plot(dat$x1,exp(lp_x1)/(1+exp(lp_x1)))

lp_x2 <- G$X[,10:18]%*%coefficients(bgam_mdl)[10:18]
plot(dat$x2,exp(lp_x2)/(1+exp(lp_x2)))

lp_x3 <- G$X[,19:27]%*%coefficients(bgam_mdl)[19:27]
plot(dat$x3,exp(lp_x3)/(1+exp(lp_x3)))

lp_x4 <- G$X[,28:36]%*%coefficients(bgam_mdl)[28:36]
plot(dat$x4,exp(lp_x4)/(1+exp(lp_x4)))

```


##